# 【风控算法】逻辑回归，贝叶斯优化

## 1. 逻辑回归

### 1. 1 逻辑回归定义

逻辑回归是一个非常常用的分类模型，模型简单，并且解释性强，在很多场景中都会被用做baseline。逻辑回归在某些书中也被称为对数几率回归，明明被叫做回归，却用在了分类问题上，我个人认为这是因为逻辑回归用了和回归类似的方法来解决了分类问题。

假设有一个二分类问题，输出为$y \in \left \{ 0，1 \right \}  $，而线性回归模型产生的预测值为$z = w^Tx + b $
是实数值，我们希望有一个理想的阶跃函数来帮我们实现$z$值到$0 / 1$值的转化。
$$
\phi (z)=\left\{\begin{matrix} 
  0,z<0 \\
  0.5,z=0\\
  1,z>0 
\end{matrix}\right. 
$$
然而该函数不连续，我们希望有一个单调可微的函数来供我们使用，于是便找到了$Sigmoid \ function$来替代。
$$
\phi (z)=\frac{1}{1+e^{-z}} 
$$
两者的图像如下图

![](https://gitee.com/zhanghang23/picture_bed/raw/master/data%20science/lr/09ef38924b66699d992579678d2e2780.png)

有了$Sigmoid \ function$之后，由于其取值在$[ 0 , 1 ]$，我们就可以将其视为类1的后验概率估计$p(y = 1|x)$。说白了，就是如果有了一个测试点x，那么就可以用$Sigmoid \ function$算出来的结果来当做该点x属于类别1的概率大小。

于是，非常自然地，我们把$Sigmoid \ function$计算得到的值大于等于0.5的归为类别1，小于0.5 的归为类别0。
$$
\hat{y}=\left\{\begin{matrix} 
  1,\text{if } \phi(z) \ge 0.5 \\  
  0,\text{otherwise} 
\end{matrix}\right. 
$$
同时逻辑回归与自适应线性网络非常相似，两者的区别在于逻辑回归的激活函数是$Sigmoid \ function$而自适应线性网络的激活函数是$y = x$ ，两者的网络结构如下图

![](https://gitee.com/zhanghang23/picture_bed/raw/master/data%20science/lr/1.png)

![](https://gitee.com/zhanghang23/picture_bed/raw/master/data%20science/lr/2.png)

### 1.2 逻辑回归代价函数

线性回归的代价函数是误差平方和，但是如果把误差平方和中带入sigmoid函数的话会发现是一个非凸函数，会有许多局部最小值，不利于求解。

则用极大似然估计来算出损失函数的参数$w$
$$
L(w)=\prod_{i=1}^{n} p(y^{(i)}|x^{(i)};w)=\prod_{i=1}^{n}(\phi(z^{(i)}))^{y^{(i)}}(1-\phi(z^{(i)}))^{(1-y^{(i)})}
$$
对上面的等式两边取对数
$$
l(w)=\ln L(w)=\sum_{i=1}^{n}({y^{(i)}}\ln(\phi(z^{(i)})+{(1-y^{(i)})}\ln(1-\phi(z^{(i)}))
$$
再在上面的$l(w)$前加负号，就得到了逻辑回归的代价函数，整个训练过程就是最小化这个结果。
$$
J(w)=-l(w)=-\sum_{i=1}^{n}({y^{(i)}}\ln(\phi(z^{(i)})+{(1-y^{(i)})}\ln(1-\phi(z^{(i)}))
$$
这个函数的表达形式是

![](https://gitee.com/zhanghang23/picture_bed/raw/master/data%20science/lr/3.png)

从图中可以看出，如果样本的值是1的话，估计值$\phi(z)$越接近1付出的代价就越小，反之越大；同理，如果样本的值是0的话，估计值$\phi(z)$越接近0付出的代价就越小，反之越大。

### 1.3 优化目标函数

LR可以用最小二乘法，也可以用梯度下降法来优化目标函数，这里介绍下梯度下降法。

梯度的负方向就是代价函数的下降最快的方向。
$$
w:=w+\triangle w,\triangle w=-\eta\frac{\partial J(w)}{\partial w_j}
$$
其中$w_j$表示第j个特征的权重；$\eta$是学习率，用来控制步长。在梯度下降更新权重的时候，只要根据
$$
w_j:=w_j+\eta\sum_{i=1}^{n}(y^{(i)}-\phi(z^{(i)}))x_j^{(i)}
$$
来更新权重即可。在样本量极大的情况下，可用随机梯度下降法来更新，这时每次迭代需要将样本重新打乱，然后不断更新权重。
$$
w_j:=w_j+\eta(y^{(i)}-\phi(z^{(i)}))x_j^{(i)}, \text{ for i in range(n)}
$$

## 2. 贝叶斯优化

贝叶斯优化是一种黑盒优化算法，用于求解表达式未知的函数的极值问题。算法根据一组采样点处的函数值预测出任意点处函数值的概率分布，这通过高斯过程回归而实现。根据高斯过程回归的结果构造采集函数，用于衡量每一个点值得探索的程度，求解采集函数的极值从而确定下一个采样点。最后返回这组采样点的极值作为函数的极值。这种算法在机器学习种被用于AutoML算法，自动确定机器学习算法的超参数。

虽然常用的超参数搜索有网格搜索和随即搜索，但是他们的效率很低，没有利用已搜索点的信息，使用这些信息指导搜索过程可以提高结果的质量以及搜索的速度。贝叶斯优化（Bayesian optimization algorithm，简称BOA）利用之前已搜索点的信息确定下一个搜索点，用于求解维数不高的黑盒优化问题。

算法的思路是首先生成一个初始候选解集合，然后根据这些点寻找下一个有可能是极值的点，将该点加入集合中，重复这一步骤，直至迭代终止。最后从这些点中找出极值点作为问题的解。

这里的关键问题是如何根据已经搜索的点确定下一个搜索点。贝叶斯优化根据已经搜索的点的函数值估计真实目标函数值的均值和方差（即波动范围），如下图的上图所示。上图中红色的曲线为估计出的目标函数值即在每一点出处的目标函数值的均值。现在有3个已经搜索的点，用黑色实心点表示。两条虚线所夹区域为在每一点处函数值的变动范围，在以均值即红色曲线为中心，与标准差成正比的区间内波动。在搜索点处，红色曲线经过搜索点，且方差最小，在远离搜索点处方差更大，这也符合我们的直观认识，远离采样点处的函数值估计的更不可靠。

![](https://gitee.com/zhanghang23/picture_bed/raw/master/data%20science/lr/4.jpg)

根据均值和方差可以构造出采集函数（acquisition function），即对每一点是函数极值点的可能性的估计，反映了每一个点值得搜索的程度，该函数的极值点是下一个搜索点，如上面图的下图所示。下图中的矩形框所表示的点是采集函数的极大值点，也是下一个搜索点。

算法的核心由两部分构成：对目标函数进行建模即计算每一点处的函数值的均值和方差，通常用高斯过程回归实现；构造采集函数，用于决定本次迭代时在哪个点处进行采样。

![](https://gitee.com/zhanghang23/picture_bed/raw/master/data%20science/lr/5.jpg)

算法首先初始化 ![[公式]](https://www.zhihu.com/equation?tex=n_%7B0%7D) 个候选解，通常在整个可行域内均匀地选取一些点。然后开始循环，每次增加一个点，直至找到 ![[公式]](https://www.zhihu.com/equation?tex=N) 个候选解。每次寻找下一个点时，用已经找到的 ![[公式]](https://www.zhihu.com/equation?tex=n) 个候选解建立高斯回归模型，得到任意点处的函数值的后验概率。然后根据后验概率构造采集函数，寻找函数的极大值点作为下一个搜索点。接下来计算在下一个搜索点处的函数值。算法最后返回 ![[公式]](https://www.zhihu.com/equation?tex=N) 个候选解的极大值作为最优解。

采集函数用于确定在何处采集下一个样本点。需要满足的条件。

1. 在已有的采样点处采集函数的值更小，因为这些点已经被探索过，再在这些点处计算函数值对解决问题没有什么用；

2. 在置信区间更宽的点处采集函数的值更大，因为这些点具有更大的不确定性，更值得探索；

3. 在函数均值更大的点处采集函数的值更大，因为均值是对该点处函数值的估计值，这些点更可能在极值点附近。

$f(x)$是一个随机变量，直接用它的数学期望$\mu(x)$作为采集函数并不是好的选择，因为没有考虑方差的影响。常用的采集函数有期望改进（expected improvement），知识梯度（knowledge gradient）等，下面以期望改进为例进行说明。假设已经搜索了$n$个点，这些点中的函数极大值记为
$$
f^*_n=\max(f(x_1),...,f(x_n))
$$
现在考虑下一个搜索点$x$，我们将计算该点的函数值$f(x)$。如果
$$
f(x)\ge f^*_n
$$
则这$n+1$个点处的函数极大值为$f(x)$，否则为$f^*_n$。对于第一种情况，加入这个心得点之后，函数值的改进为$f(x)-f^*_n$，对于第二种情况，则为0。借助截断函数
$$
a^+=\max(a,0)
$$
我们可以将加入新的点之后的改进值写成$[f(x)-f^*_n]^+$。

现在的目标是找到使得上面的改进值最大的$x$，但该点处的函数值 $f(x)$ 在我们找到这个点 ![[公式]](https://www.zhihu.com/equation?tex=x) 并进行函数值计算之前又是未知的。由于我们知道 $f(x)$的概率分布，因此我们可以计算所有 $x$ 处的改进值的数学期望。并选择数学期望最大的 $x$作为下一个探索点。因此可以定义下面的期望改进（expected improvement)函数
$$
EI_n(x)=E_n[[f(x)-f^*_n]^+]
$$
其中$E_n[\cdot]=E[\cdot|x_{1:n},y_{1:n}]$表示根据前面$n$个采样点$x_1,...,x_n$以及这些点处的函数值$y_1,...,y_n$计算出的条件期望值。计算这个数学期望所采用的概率分布由高斯过程回归定义，是$f(x)$的条件概率。

由于高斯过程回归假设$f(x)$服从正态分布，可以得到数学期望的解析表达式。假设在 ![[公式]](https://www.zhihu.com/equation?tex=x) 点处的均值为$\mu=\mu(x)$，方差为
$$
\sigma^2=\sigma^2(x)
$$
。令$z=f(x)$，根据数学期望的定义有
$$
\begin{array}{l}  
  EI_n(x)=\int_{-\infty }^{+\infty}[z-f^*_n]^+\frac{1}{\sqrt{2\pi}\sigma }\exp(-\frac{(z-\mu)^2}{2\sigma^2})dz  \\  
  =\int_{f_n^*}^{+\infty}(z-f^*_n)\frac{1}{\sqrt{2\pi}\sigma }\exp(-\frac{(z-\mu)^2}{2\sigma^2})dz
\end{array}
$$
使用定积分的换元法，可以得到
$$
\begin{array}{l}  
  \int_{f_n^*}^{+\infty}(z-f^*_n)\frac{1}{\sqrt{2\pi}\sigma }\exp(-\frac{(z-\mu)^2}{2\sigma^2})dz  \\  
  =(\mu-f^*_n)(1-\Phi ((f_n^*-\mu)/\sigma))+\sigma\varphi((f^*_n-\mu)/\sigma) 
\end{array}
$$
其中$\varphi(x)$为标准正态分布的概率密度函数，$\Phi(x)$是标准正态分布的分布函数。如果令
$$
\triangle (x)=\mu(x)-f_n^*
$$
，则有
$$
EI_n(x)=[\triangle(x)]^++\sigma(x)\varphi(\frac{\triangle(x)}{\sigma(x)}-|\triangle(x)|\Phi(\frac{\triangle(x)}{\sigma(x)})
$$
其中$\mu(x),\sigma^2(x)$是x的函数，因此EI也是x的函数。期望改进将每个点处的期望改进表示为该点的函数，下一步是求期望改进函数的极值以得到下一个采样点
$$
x_{n+1}=\arg\max EI_n(x)
$$
这个问题易于求解。由于可以得到目标函数的一阶和二阶导数，因此梯度下降法和L-BFGS算法都可以解决此问题。

